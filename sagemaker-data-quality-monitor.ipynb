{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.123.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "sagemaker_client = sagemaker_session.sagemaker_client\n",
    "sagemaker_runtime_client = sagemaker_session.sagemaker_runtime_client\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.clarify import (\n",
    "    BiasConfig,\n",
    "    DataConfig,\n",
    "    ModelConfig,\n",
    "    ModelPredictedLabelConfig,\n",
    "    SHAPConfig,\n",
    ")\n",
    "\n",
    "from sagemaker.model_monitor import (\n",
    "    BiasAnalysisConfig,\n",
    "    CronExpressionGenerator,\n",
    "    DataCaptureConfig,\n",
    "    EndpointInput,\n",
    "    ExplainabilityAnalysisConfig,\n",
    "    ModelBiasMonitor,\n",
    "    ModelExplainabilityMonitor,\n",
    "    DefaultModelMonitor,\n",
    "    ModelQualityMonitor,\n",
    ")\n",
    "\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a30849",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure data capture and generate synthetic traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f63184",
   "metadata": {},
   "source": [
    "Data quality monitoring automatically monitors machine learning (ML) models in production and notifies you when data quality issues arise. ML models in production have to make predictions on real-life data that is not carefully curated like most training datasets. If the statistical nature of the data that your model receives while in production drifts away from the nature of the baseline data it was trained on, the model begins to lose accuracy in its predictions. Amazon SageMaker Model Monitor uses rules to detect data drift and alerts you when it happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ea127",
   "metadata": {},
   "source": [
    "### Initialize SageMaker Predictor for real-time requests to previously deployed model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc19dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Predictor Python object for real-time endpoint requests. https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "predictor = Predictor(endpoint_name=endpoint_name, serializer=CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker automatically created a DataCaptureConfig when your model was deployed to an endpoint \n",
    "# in a prior lab that already had data capture enabled. Below is illustrating how create a custom \n",
    "# DataCaptureConfig with data capture enabled and update an existing endpoint.\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=s3_capture_upload_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c684e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now update endpoint with data capture enabled and provide an s3_capture_upload_path.\n",
    "predictor.update_data_capture_config(data_capture_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abcdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training set for schema and to compute feature attribution baselines.\n",
    "train_df = pd.read_csv(\"train-headers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sending test traffic to the endpoint {}. \\nPlease wait...\".format(endpoint_name))\n",
    "\n",
    "test_sample_df = pd.read_csv('test-samples-no-header.csv', header = None, index_col = False)\n",
    "\n",
    "response = predictor.predict(data=test_sample_df.to_numpy())\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eef988",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting 60 seconds for captures to show up\", end=\"\")\n",
    "\n",
    "for _ in range(60):\n",
    "    capture_files = sorted(S3Downloader.list(f\"{s3_capture_upload_path}\"))\n",
    "    if capture_files:\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\nFound Capture Files:\")\n",
    "print(\"\\n \".join(capture_files[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")[-10:-1]\n",
    "print(capture_file[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2fe0ad",
   "metadata": {},
   "source": [
    "View a single line is present below in a formatted JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473db6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(json.loads(capture_file[-1]), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class WorkerThread(threading.Thread):\n",
    "    def __init__(self, do_run, *args, **kwargs):\n",
    "        super(WorkerThread, self).__init__(*args, **kwargs)\n",
    "        self.__do_run = do_run\n",
    "        self.__terminate_event = threading.Event()\n",
    "\n",
    "    def terminate(self):\n",
    "        self.__terminate_event.set()\n",
    "\n",
    "    def run(self):\n",
    "        while not self.__terminate_event.is_set():\n",
    "            self.__do_run(self.__terminate_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c332d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_endpoint(terminate_event):\n",
    "    with open(\"test-samples-no-header.csv\", \"r\") as f:\n",
    "        i = 0\n",
    "        for row in f:\n",
    "            payload = row.rstrip(\"\\n\")\n",
    "            response = sagemaker_runtime_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType=\"text/csv\",\n",
    "                Body=payload,\n",
    "                InferenceId=str(i),  # unique ID per row\n",
    "            )\n",
    "            i += 1\n",
    "            response[\"Body\"].read()\n",
    "            time.sleep(1)\n",
    "            if terminate_event.is_set():\n",
    "                break\n",
    "\n",
    "\n",
    "# Keep invoking the endpoint with test data\n",
    "invoke_endpoint_thread = WorkerThread(do_run=invoke_endpoint)\n",
    "invoke_endpoint_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quality_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ea60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_quality_baseline_job_name = f\"DataQualityBaselineJob-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "data_quality_baseline_job = data_quality_monitor.suggest_baseline(\n",
    "    job_name=data_quality_baseline_job_name,\n",
    "    baseline_dataset=\"train-headers.csv\",\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    ")\n",
    "\n",
    "data_quality_baseline_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_data_quality_baseline_job = data_quality_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(latest_data_quality_baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_df = pd.json_normalize(latest_data_quality_baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a2008",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a data quality monitoring schedule name.\n",
    "data_quality_monitor_schedule_name = (\n",
    "    f\"xgboost-dm-data-monitoring-schedule-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ad9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EndpointInput\n",
    "endpointInput = EndpointInput(\n",
    "    endpoint_name=predictor.endpoint_name,\n",
    "    destination=\"/opt/ml/processing/input_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62271c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where to write the data quality monitoring results report to.\n",
    "data_quality_baseline_job_result_uri = f\"{s3_baseline_results_path}/data_quality\"\n",
    "\n",
    "response = data_quality_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=data_quality_monitor_schedule_name,\n",
    "    endpoint_input=endpointInput,\n",
    "    output_s3_uri=data_quality_baseline_job_result_uri,\n",
    "    constraints=latest_data_quality_baseline_job.suggested_constraints(),\n",
    "    # Create the monitoring schedule to execute every hour.    \n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will see the monitoring schedule in the 'Scheduled' status\n",
    "data_quality_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8829393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check default model monitor created.\n",
    "predictor.list_monitors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5088dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially there will be no executions since the first execution happens at the top of the hour\n",
    "# Note that it is common for the execution to launch upto 20 min after the hour.\n",
    "executions = data_quality_monitor.list_executions()\n",
    "executions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2461a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint_thread.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2eb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_monitors = predictor.list_monitors()\n",
    "\n",
    "for monitor in model_monitors:\n",
    "    monitor.stop_monitoring_schedule()\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
