{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaed67f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.123.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35a7df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "sagemaker_client = sagemaker_session.sagemaker_client\n",
    "sagemaker_runtime_client = sagemaker_session.sagemaker_runtime_client\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.clarify import (\n",
    "    BiasConfig,\n",
    "    DataConfig,\n",
    "    ModelConfig,\n",
    "    ModelPredictedLabelConfig,\n",
    "    SHAPConfig,\n",
    ")\n",
    "\n",
    "from sagemaker.model_monitor import (\n",
    "    BiasAnalysisConfig,\n",
    "    CronExpressionGenerator,\n",
    "    DataCaptureConfig,\n",
    "    EndpointInput,\n",
    "    ExplainabilityAnalysisConfig,\n",
    "    ModelBiasMonitor,\n",
    "    ModelExplainabilityMonitor,\n",
    "    DefaultModelMonitor,\n",
    "    ModelQualityMonitor,\n",
    ")\n",
    "\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b7afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"AWS region: {region}\")\n",
    "# A different bucket can be used, but make sure the role for this notebook has\n",
    "# the s3:PutObject permissions. This is the bucket into which the data is captured.\n",
    "print(f\"S3 Bucket: {default_bucket}\")\n",
    "\n",
    "# Endpoint metadata.\n",
    "# Note: you will use the staging endpoint from the previously lab just as you would in a real scenario to verify your monitoring\n",
    "# setup before deploying your setup on production endpoints.\n",
    "endpoint_name = \"workshop-project-staging\"\n",
    "endpoint_instance_count = 1\n",
    "endpoint_instance_type = \"ml.m5.large\"\n",
    "print(f\"Endpoint: {endpoint_name}\")\n",
    "\n",
    "prefix = \"sagemaker/xgboost-dm-model-monitoring\"\n",
    "s3_key = f\"s3://{default_bucket}/{prefix}\"\n",
    "print(f\"S3 key: {s3_key}\")\n",
    "\n",
    "s3_capture_upload_path = f\"{s3_key}/data_capture\"\n",
    "s3_ground_truth_upload_path = f\"{s3_key}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "s3_baseline_results_path = f\"{s3_key}/baselines\"\n",
    "s3_report_path = f\"{s3_key}/reports\"\n",
    "\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Ground truth path: {s3_ground_truth_upload_path}\")\n",
    "print(f\"Baselines path: {s3_baseline_results_path}\")\n",
    "print(f\"Report path: {s3_report_path}\")\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "endpoint_config = sm_client.describe_endpoint(EndpointName = endpoint_name)['EndpointConfigName']\n",
    "model_name = sm_client.describe_endpoint_config(EndpointConfigName = endpoint_config)['ProductionVariants'][0]['ModelName']\n",
    "\n",
    "print(\"Model Name : \", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e70ac96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Predictor Python object for real-time endpoint requests. https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html\n",
    "predictor = Predictor(endpoint_name=endpoint_name, serializer=CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7824a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in training set for schema and to compute feature attribution baselines.\n",
    "train_df = pd.read_csv(\"train-headers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa06809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use test set to create a file without headers and labels to mirror data format at inference time.\n",
    "test_df = pd.read_csv(\"test.csv\", header = None)\n",
    "test_df.drop(test_df.columns[0], axis=1, inplace=True)\n",
    "test_df.sample(180).to_csv('test-samples-no-header.csv', header = False, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e15b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Sending test traffic to the endpoint {}. \\nPlease wait...\".format(endpoint_name))\n",
    "\n",
    "test_sample_df = pd.read_csv('test-samples-no-header.csv', header = None, index_col = False)\n",
    "\n",
    "response = predictor.predict(data=test_sample_df.to_numpy())\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd02f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Waiting 60 seconds for captures to show up\", end=\"\")\n",
    "\n",
    "for _ in range(60):\n",
    "    capture_files = sorted(S3Downloader.list(f\"{s3_capture_upload_path}/{endpoint_name}\"))\n",
    "    if capture_files:\n",
    "        break\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\nFound Capture Files:\")\n",
    "print(\"\\n \".join(capture_files[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb86020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")[-10:-1]\n",
    "print(capture_file[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95356ebe",
   "metadata": {},
   "source": [
    "View a single line is present below in a formatted JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec986c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(json.dumps(json.loads(capture_file[-1]), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d598c45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class WorkerThread(threading.Thread):\n",
    "    def __init__(self, do_run, *args, **kwargs):\n",
    "        super(WorkerThread, self).__init__(*args, **kwargs)\n",
    "        self.__do_run = do_run\n",
    "        self.__terminate_event = threading.Event()\n",
    "\n",
    "    def terminate(self):\n",
    "        self.__terminate_event.set()\n",
    "\n",
    "    def run(self):\n",
    "        while not self.__terminate_event.is_set():\n",
    "            self.__do_run(self.__terminate_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b1fa72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_endpoint(terminate_event):\n",
    "    with open(\"test-samples-no-header.csv\", \"r\") as f:\n",
    "        i = 0\n",
    "        for row in f:\n",
    "            payload = row.rstrip(\"\\n\")\n",
    "            response = sagemaker_runtime_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name,\n",
    "                ContentType=\"text/csv\",\n",
    "                Body=payload,\n",
    "                InferenceId=str(i),  # unique ID per row\n",
    "            )\n",
    "            i += 1\n",
    "            response[\"Body\"].read()\n",
    "            time.sleep(1)\n",
    "            if terminate_event.is_set():\n",
    "                break\n",
    "\n",
    "\n",
    "# Keep invoking the endpoint with test data\n",
    "invoke_endpoint_thread = WorkerThread(do_run=invoke_endpoint)\n",
    "invoke_endpoint_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d47ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def ground_truth_with_id(inference_id):\n",
    "    # set random seed to get consistent results.\n",
    "    random.seed(inference_id) \n",
    "    rand = random.random()\n",
    "    # format required by the merge container.\n",
    "    return {\n",
    "        \"groundTruthData\": {\n",
    "            # randomly generate positive labels 70% of the time.\n",
    "            \"data\": \"1\" if rand < 0.7 else \"0\",\n",
    "            \"encoding\": \"CSV\",\n",
    "        },\n",
    "        \"eventMetadata\": {\n",
    "            \"eventId\": str(inference_id),\n",
    "        },\n",
    "        \"eventVersion\": \"0\",\n",
    "    }\n",
    "\n",
    "\n",
    "def upload_ground_truth(upload_time):\n",
    "    # 180 are the number of rows in data we're sending for inference.\n",
    "    records = [ground_truth_with_id(i) for i in range(180)]\n",
    "    fake_records = [json.dumps(r) for r in records]\n",
    "    data_to_upload = \"\\n\".join(fake_records)\n",
    "    target_s3_uri = f\"{s3_ground_truth_upload_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    print(f\"Uploading {len(fake_records)} records to\", target_s3_uri)\n",
    "    S3Uploader.upload_string_as_file_body(data_to_upload, target_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecabb140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate data for the last hour.\n",
    "upload_ground_truth(datetime.utcnow() - timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09dd11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also use the WorkerThread class to continue generating synthetic ground truth data once an hour.\n",
    "def generate_fake_ground_truth(terminate_event):\n",
    "    upload_ground_truth(datetime.utcnow())\n",
    "    for _ in range(0, 60):\n",
    "        time.sleep(60)\n",
    "        if terminate_event.is_set():\n",
    "            break\n",
    "\n",
    "\n",
    "ground_truth_thread = WorkerThread(do_run=generate_fake_ground_truth)\n",
    "ground_truth_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53342fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855ef9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_quality_baseline_job_name = f\"ModelQualityBaselineJob-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "model_quality_baseline_job_result_uri = f\"{s3_baseline_results_path}/model_quality\"\n",
    "\n",
    "model_quality_baseline_job = model_quality_monitor.suggest_baseline(\n",
    "    job_name=model_quality_baseline_job_name,\n",
    "    baseline_dataset=\"validation-with-predictions.csv\", # The S3 location of the validation dataset.\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri = model_quality_baseline_job_result_uri, # The S3 location to store the results.\n",
    "    problem_type=\"BinaryClassification\",\n",
    "    inference_attribute= \"prediction\", # The column in the dataset that contains predictions.\n",
    "    probability_attribute= \"probability\", # The column in the dataset that contains probabilities.\n",
    "    ground_truth_attribute= \"label\" # The column in the dataset that contains ground truth labels.\n",
    ")\n",
    "\n",
    "model_quality_baseline_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d08356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latest_model_quality_baseline_job = model_quality_monitor.latest_baselining_job\n",
    "pd.DataFrame(latest_model_quality_baseline_job.suggested_constraints().body_dict[\"binary_classification_constraints\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3279416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_quality_monitor_schedule_name = (\n",
    "    f\"xgboost-dm-model-monitoring-schedule-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea26090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an EndpointInput configuration.\n",
    "endpointInput = EndpointInput(\n",
    "    endpoint_name=predictor.endpoint_name,\n",
    "    probability_attribute=\"0\",\n",
    "    probability_threshold_attribute=0.5,\n",
    "    destination=\"/opt/ml/processing/input_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ef352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a monitoring schedule.\n",
    "response = model_quality_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=model_quality_monitor_schedule_name,\n",
    "    endpoint_input=endpointInput,\n",
    "    output_s3_uri=model_quality_baseline_job_result_uri,\n",
    "    problem_type=\"BinaryClassification\",\n",
    "    ground_truth_input=s3_ground_truth_upload_path,\n",
    "    constraints=latest_model_quality_baseline_job.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ba68bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the model monitor was created.\n",
    "predictor.list_monitors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa14eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You will see the monitoring schedule in the 'Scheduled' status.\n",
    "model_quality_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially there will be no executions since the first execution happens at the top of the hour\n",
    "# Note that it is common for the execution to launch up to 20 min after the hour.\n",
    "executions = model_quality_monitor.list_executions()\n",
    "executions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ca395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint_thread.terminate()\n",
    "ground_truth_thread.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_monitors = predictor.list_monitors()\n",
    "\n",
    "for monitor in model_monitors:\n",
    "    monitor.stop_monitoring_schedule()\n",
    "    monitor.delete_monitoring_schedule()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
